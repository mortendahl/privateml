{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from functools import reduce\n",
    "from scipy.special import comb\n",
    "binom = lambda n, k: comb(n, k, exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = 2657003489534545107915232808830590043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.arange(27).reshape(3,3,3)\n",
    "w = np.arange(27).reshape(3,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor of public values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PublicTensor:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "    \n",
    "    def reveal(self):\n",
    "        return self\n",
    "    \n",
    "    def unwrap(self):\n",
    "        return self.values\n",
    "    \n",
    "    def add(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            values = (x.values + y.values) % Q\n",
    "            return PublicTensor(values)\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values + y.shares0) % Q\n",
    "            shares1 =             y.shares1\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        \n",
    "    def sub(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            values = (x.values - y.values) % Q\n",
    "            return PublicTensor(values)\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values + Q - y.shares0) % Q\n",
    "            shares1 = (           Q - y.shares1) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        \n",
    "    def mul(x, y):\n",
    "        if isinstance(y, PublicTensor):\n",
    "            values = (x.values * y.values) % Q\n",
    "            return PublicTensor(values)\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = (x.values * y.shares0) % Q\n",
    "            shares1 = (x.values * y.shares1) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "    \n",
    "    def dot(x, y):\n",
    "        if isinstance(y, PublicTensor): \n",
    "            values = x.values.dot(y.values) % Q\n",
    "            return PublicTensor(values)\n",
    "        if isinstance(y, PrivateTensor):\n",
    "            shares0 = x.values.dot(y.shares0) % Q\n",
    "            shares1 = x.values.dot(y.shares1) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "    \n",
    "    def pows(x, highest_power):\n",
    "        x_powers = ( np.power(x.values, e) % Q for e in range(0, highest_power+1) )\n",
    "        return [ PublicTensor(v) for v in x_powers ]\n",
    "    \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "    \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.values.shape\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"PublicTensor(\\n%s)\" % self.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PublicTensor(v)\n",
    "y = PublicTensor(w)\n",
    "\n",
    "z = x + y; assert (z.unwrap() == v + w).all()\n",
    "z = x - y; assert (z.unwrap() == v - w).all()\n",
    "z = x * y; assert (z.unwrap() == v * w).all()\n",
    "z = x.dot(y); assert (z.unwrap() == v.dot(w)).all()\n",
    "\n",
    "z = x.pows(2); \n",
    "assert (z[0].unwrap() == v**0).all\n",
    "assert (z[1].unwrap() == v**1).all\n",
    "assert (z[2].unwrap() == v**2).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor of private values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_random_tensor(shape):\n",
    "    values = [ random.randrange(Q) for _ in range(np.prod(shape)) ]\n",
    "    return np.array(values).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_mul_triple(x_shape, y_shape):\n",
    "    a = sample_random_tensor(x_shape)\n",
    "    b = sample_random_tensor(y_shape)\n",
    "    c = np.multiply(a, b) % Q\n",
    "    return PrivateTensor(a), PrivateTensor(b), PrivateTensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dot_triple(x_shape, y_shape):\n",
    "    a = sample_random_tensor(x_shape)\n",
    "    b = sample_random_tensor(y_shape)\n",
    "    c = np.dot(a, b) % Q\n",
    "    return PrivateTensor(a), PrivateTensor(b), PrivateTensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "#  - use eg repeated squaring instead, but NumPy doesn't support that\n",
    "#  - avoid resharing '1' every time\n",
    "\n",
    "def generate_pows_triple(shape, highest_power):\n",
    "    a = random_values(shape)\n",
    "#     a = np.zeros(shape).astype('int').astype('object')\n",
    "    a_powers = ( np.power(a, e) % Q for e in range(0, highest_power+1) )\n",
    "    return [ PrivateTensor(v) for v in a_powers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrivateTensor:\n",
    "    \n",
    "    def __init__(self, values, shares0=None, shares1=None):\n",
    "        if not values is None:\n",
    "            shares0 = sample_random_tensor(x.shape)\n",
    "            shares1 = (values - shares0) % Q\n",
    "        self.shares0 = shares0\n",
    "        self.shares1 = shares1\n",
    "    \n",
    "    def reconstruct(self):\n",
    "        return PublicTensor((self.shares0 + self.shares1) % Q)\n",
    "    \n",
    "    def unwrap(self):\n",
    "        return (self.shares0 + self.shares1) % Q\n",
    "    \n",
    "    def add(x, y):\n",
    "        if type(y) is PublicTensor:\n",
    "            shares0 = (x.shares0 + y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        if type(y) is PrivateTensor:\n",
    "            shares0 = (x.shares0 + y.shares0) % Q\n",
    "            shares1 = (x.shares1 + y.shares1) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "    \n",
    "    def sub(x, y):\n",
    "        if type(y) is PublicTensor:\n",
    "            shares0 = (x.shares0 - y.values) % Q\n",
    "            shares1 =  x.shares1\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        if type(y) is PrivateTensor:\n",
    "            shares0 = (x.shares0 - y.shares0) % Q\n",
    "            shares1 = (x.shares1 - y.shares1) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "           \n",
    "    def mul(x, y):\n",
    "        if type(y) is PublicTensor:\n",
    "            shares0 = (x.shares0 * y.values) % Q\n",
    "            shares1 = (x.shares1 * y.values) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        if type(y) is PrivateTensor:\n",
    "            a, b, c = generate_mul_triple(x.shape, y.shape)\n",
    "            alpha = (x - a).reconstruct()\n",
    "            beta  = (y - b).reconstruct()\n",
    "            return alpha.mul(beta) + \\\n",
    "                   alpha.mul(b) + \\\n",
    "                   a.mul(beta) + \\\n",
    "                   c\n",
    "                    \n",
    "    def dot(x, y):\n",
    "        if type(y) is PublicTensor:\n",
    "            shares0 = x.shares0.dot(y.values) % Q\n",
    "            shares1 = x.shares1.dot(y.values) % Q\n",
    "            return PrivateTensor(None, shares0, shares1)\n",
    "        if type(y) is PrivateTensor:\n",
    "            a, b, c = generate_dot_triple(x.shape, y.shape)\n",
    "            alpha = (x - a).reconstruct()\n",
    "            beta  = (y - b).reconstruct()\n",
    "            return alpha.dot(beta) + \\\n",
    "                   alpha.dot(b) + \\\n",
    "                   a.dot(beta) + \\\n",
    "                   c\n",
    "    \n",
    "    def conv2d(x, y):\n",
    "        pass\n",
    "    \n",
    "    def pows(x, highest_power):\n",
    "        assert highest_power >= 1        \n",
    "        a_powers = generate_pows_triple(x.shape, highest_power)\n",
    "        one = a_powers[0]\n",
    "        a = a_powers[1]\n",
    "        alpha = (x - a).reveal()\n",
    "        alpha_powers = alpha.pows(highest_power)\n",
    "        x_powers = []\n",
    "        for power in range(1, highest_power+2):\n",
    "            # compute binomial coefficients\n",
    "            coeffs = [ PublicTensor(binom(power, k)) for k in range(power+1) ]\n",
    "            # compute and sum terms\n",
    "            foo = a_powers[:power+1]\n",
    "            bar = list(reversed(alpha_powers[:power]))\n",
    "            print(len(foo), len(bar))\n",
    "            terms = [\n",
    "                a_power * (alpha_power * coeff) \\\n",
    "                for a_power, alpha_power, coeff in zip (\\\n",
    "                    foo,\n",
    "                    bar,\n",
    "                    coeffs\n",
    "                )\n",
    "            ]\n",
    "            x_powers.append(reduce(lambda x, y: x + y, terms))\n",
    "        return x_powers\n",
    "        \n",
    "    def __add__(x, y):\n",
    "        return x.add(y)\n",
    "            \n",
    "    def __sub__(x, y):\n",
    "        return x.sub(y)\n",
    "    \n",
    "    def __mul__(x, y):\n",
    "        return x.mul(y)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.shares0.shape\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"PrivateTensor(\\n%s)\" % reconstruct(self.shares0, self.shares1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PrivateTensor(v)\n",
    "y = PrivateTensor(w)\n",
    "\n",
    "z = x + y; assert (z.unwrap() == v + w).all()\n",
    "z = x - y; assert (z.unwrap() == v - w).all()\n",
    "z = x * y; assert (z.unwrap() == v * w).all()\n",
    "z = x.dot(y); assert (z.unwrap() == v.dot(w)).all()\n",
    "\n",
    "# z = x.pows(2);\n",
    "# print(len(z), z)\n",
    "# assert (z[0].unwrap() == v**0).all()\n",
    "# assert (z[1].unwrap() == v**1).all()\n",
    "# assert (z[2].unwrap() == v**2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
