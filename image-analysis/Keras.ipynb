{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = dataset\n",
    "    \n",
    "    # NOTE: this is the shape used by Tensorflow; other backends may differ\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    x_train  = x_train.astype('float32')\n",
    "    x_test   = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test  /= 255\n",
    "\n",
    "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test  = to_categorical(y_test, NUM_CLASSES)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train_public = x_train[y_train < 5]\n",
    "    y_train_public = y_train[y_train < 5]\n",
    "    x_test_public  = x_test[y_test < 5]\n",
    "    y_test_public  = y_test[y_test < 5]\n",
    "    public_dataset = (x_train_public, y_train_public), (x_test_public, y_test_public)\n",
    "\n",
    "    x_train_private = x_train[y_train >= 5]\n",
    "    y_train_private = y_train[y_train >= 5] - 5\n",
    "    x_test_private  = x_test[y_test >= 5]\n",
    "    y_test_private  = y_test[y_test >= 5] - 5\n",
    "    private_dataset = (x_train_private, y_train_private), (x_test_private, y_test_private)\n",
    "    \n",
    "    return preprocess_data(public_dataset), preprocess_data(private_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full training\n",
    "\n",
    "From https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py \n",
    "\n",
    "but see also https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/1\n",
      "29404/29404 [==============================] - 100s - loss: 0.1354 - acc: 0.9554 - val_loss: 0.0380 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129675eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, private_dataset = load_data()\n",
    "(x_train, y_train), (x_test, y_test) = private_dataset\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(.50),\n",
    "    Dense(NUM_CLASSES),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the optimizer: switching to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/1\n",
      "29404/29404 [==============================] - 107s - loss: 0.4435 - acc: 0.8463 - val_loss: 0.1595 - val_acc: 0.9488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b78bf60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, private_dataset = load_data()\n",
    "(x_train, y_train), (x_test, y_test) = private_dataset\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(.50),\n",
    "    Dense(NUM_CLASSES),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(clipnorm=10000, clipvalue=10000),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting rid of comparisons: sigmoid activations and average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/25\n",
      "29404/29404 [==============================] - 118s - loss: 1.6875 - acc: 0.2064 - val_loss: 1.6238 - val_acc: 0.2115\n",
      "Epoch 2/25\n",
      "29404/29404 [==============================] - 115s - loss: 1.6427 - acc: 0.1991 - val_loss: 1.6140 - val_acc: 0.1835\n",
      "Epoch 3/25\n",
      "29404/29404 [==============================] - 108s - loss: 1.6210 - acc: 0.2016 - val_loss: 1.6130 - val_acc: 0.2115\n",
      "Epoch 4/25\n",
      "29404/29404 [==============================] - 105s - loss: 1.6149 - acc: 0.2068 - val_loss: 1.6103 - val_acc: 0.2115\n",
      "Epoch 5/25\n",
      "29404/29404 [==============================] - 98s - loss: 1.6157 - acc: 0.2043 - val_loss: 1.6210 - val_acc: 0.2115\n",
      "Epoch 6/25\n",
      "29404/29404 [==============================] - 114s - loss: 1.6145 - acc: 0.2050 - val_loss: 1.6124 - val_acc: 0.2076\n",
      "Epoch 7/25\n",
      "29404/29404 [==============================] - 116s - loss: 1.6144 - acc: 0.2047 - val_loss: 1.6124 - val_acc: 0.2004\n",
      "Epoch 8/25\n",
      "29404/29404 [==============================] - 108s - loss: 1.6146 - acc: 0.2003 - val_loss: 1.6116 - val_acc: 0.2076\n",
      "Epoch 9/25\n",
      "29404/29404 [==============================] - 86s - loss: 1.6147 - acc: 0.2074 - val_loss: 1.6155 - val_acc: 0.2004\n",
      "Epoch 10/25\n",
      "29404/29404 [==============================] - 87s - loss: 1.6141 - acc: 0.2068 - val_loss: 1.6261 - val_acc: 0.2004\n",
      "Epoch 11/25\n",
      "29404/29404 [==============================] - 87s - loss: 1.6154 - acc: 0.2033 - val_loss: 1.6129 - val_acc: 0.2004\n",
      "Epoch 12/25\n",
      "29404/29404 [==============================] - 87s - loss: 1.6145 - acc: 0.2038 - val_loss: 1.6137 - val_acc: 0.1971\n",
      "Epoch 13/25\n",
      "29404/29404 [==============================] - 87s - loss: 1.6142 - acc: 0.2071 - val_loss: 1.6161 - val_acc: 0.2115\n",
      "Epoch 14/25\n",
      "29404/29404 [==============================] - 118s - loss: 1.6153 - acc: 0.2055 - val_loss: 1.6127 - val_acc: 0.2076\n",
      "Epoch 15/25\n",
      "29404/29404 [==============================] - 125s - loss: 1.6154 - acc: 0.2009 - val_loss: 1.6125 - val_acc: 0.2115\n",
      "Epoch 16/25\n",
      "29404/29404 [==============================] - 124s - loss: 1.6148 - acc: 0.2046 - val_loss: 1.6159 - val_acc: 0.2076\n",
      "Epoch 17/25\n",
      "29404/29404 [==============================] - 120s - loss: 1.6139 - acc: 0.2052 - val_loss: 1.6152 - val_acc: 0.1835\n",
      "Epoch 18/25\n",
      "29404/29404 [==============================] - 100s - loss: 1.6143 - acc: 0.2071 - val_loss: 1.6222 - val_acc: 0.1971\n",
      "Epoch 19/25\n",
      "29404/29404 [==============================] - 99s - loss: 1.6147 - acc: 0.2069 - val_loss: 1.6142 - val_acc: 0.1971\n",
      "Epoch 20/25\n",
      "29404/29404 [==============================] - 101s - loss: 0.7185 - acc: 0.6911 - val_loss: 0.1630 - val_acc: 0.9469\n",
      "Epoch 21/25\n",
      "29404/29404 [==============================] - 101s - loss: 0.2201 - acc: 0.9272 - val_loss: 0.1240 - val_acc: 0.9607\n",
      "Epoch 22/25\n",
      "29404/29404 [==============================] - 101s - loss: 0.1664 - acc: 0.9442 - val_loss: 0.0844 - val_acc: 0.9735\n",
      "Epoch 23/25\n",
      "29404/29404 [==============================] - 839s - loss: 0.1353 - acc: 0.9570 - val_loss: 0.0742 - val_acc: 0.9743\n",
      "Epoch 24/25\n",
      "29404/29404 [==============================] - 125s - loss: 0.1141 - acc: 0.9622 - val_loss: 0.0638 - val_acc: 0.9792\n",
      "Epoch 25/25\n",
      "29404/29404 [==============================] - 134s - loss: 0.1050 - acc: 0.9663 - val_loss: 0.0529 - val_acc: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126c1f358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, private_dataset = load_data()\n",
    "(x_train, y_train), (x_test, y_test) = private_dataset\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(NUM_CLASSES),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting rid of logarithms: MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/25\n",
      "29404/29404 [==============================] - 113s - loss: 0.1609 - acc: 0.2026 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 2/25\n",
      "29404/29404 [==============================] - 115s - loss: 0.1600 - acc: 0.2088 - val_loss: 0.1601 - val_acc: 0.2115\n",
      "Epoch 3/25\n",
      "29404/29404 [==============================] - 89s - loss: 0.1600 - acc: 0.2104 - val_loss: 0.1600 - val_acc: 0.2115\n",
      "Epoch 4/25\n",
      "29404/29404 [==============================] - 1493s - loss: 0.1600 - acc: 0.2102 - val_loss: 0.1600 - val_acc: 0.1971\n",
      "Epoch 5/25\n",
      "29404/29404 [==============================] - 101s - loss: 0.1600 - acc: 0.2101 - val_loss: 0.1599 - val_acc: 0.2076\n",
      "Epoch 6/25\n",
      "29404/29404 [==============================] - 87s - loss: 0.1600 - acc: 0.2081 - val_loss: 0.1600 - val_acc: 0.1971\n",
      "Epoch 7/25\n",
      "29404/29404 [==============================] - 85s - loss: 0.1600 - acc: 0.2064 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 8/25\n",
      "29404/29404 [==============================] - 96s - loss: 0.1600 - acc: 0.2095 - val_loss: 0.1600 - val_acc: 0.2115\n",
      "Epoch 9/25\n",
      "29404/29404 [==============================] - 107s - loss: 0.1600 - acc: 0.2091 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 10/25\n",
      "29404/29404 [==============================] - 118s - loss: 0.1600 - acc: 0.2068 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 11/25\n",
      "29404/29404 [==============================] - 111s - loss: 0.1600 - acc: 0.2090 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 12/25\n",
      "29404/29404 [==============================] - 102s - loss: 0.1600 - acc: 0.2109 - val_loss: 0.1600 - val_acc: 0.2076\n",
      "Epoch 13/25\n",
      "29404/29404 [==============================] - 112s - loss: 0.1599 - acc: 0.2078 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 14/25\n",
      "29404/29404 [==============================] - 102s - loss: 0.1599 - acc: 0.2114 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 15/25\n",
      "29404/29404 [==============================] - 98s - loss: 0.1600 - acc: 0.2108 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 16/25\n",
      "29404/29404 [==============================] - 96s - loss: 0.1599 - acc: 0.2125 - val_loss: 0.1599 - val_acc: 0.2115\n",
      "Epoch 17/25\n",
      "29404/29404 [==============================] - 88s - loss: 0.1599 - acc: 0.2174 - val_loss: 0.1595 - val_acc: 0.2115\n",
      "Epoch 18/25\n",
      "29404/29404 [==============================] - 96s - loss: 0.1048 - acc: 0.5560 - val_loss: 0.0279 - val_acc: 0.9120\n",
      "Epoch 19/25\n",
      "29404/29404 [==============================] - 107s - loss: 0.0268 - acc: 0.9130 - val_loss: 0.0179 - val_acc: 0.9434\n",
      "Epoch 20/25\n",
      "29404/29404 [==============================] - 116s - loss: 0.0204 - acc: 0.9346 - val_loss: 0.0150 - val_acc: 0.9498\n",
      "Epoch 21/25\n",
      "29404/29404 [==============================] - 120s - loss: 0.0172 - acc: 0.9447 - val_loss: 0.0141 - val_acc: 0.9549\n",
      "Epoch 22/25\n",
      "29404/29404 [==============================] - 91s - loss: 0.0154 - acc: 0.9512 - val_loss: 0.0118 - val_acc: 0.9621\n",
      "Epoch 23/25\n",
      "29404/29404 [==============================] - 86s - loss: 0.0144 - acc: 0.9533 - val_loss: 0.0111 - val_acc: 0.9636\n",
      "Epoch 24/25\n",
      "29404/29404 [==============================] - 105s - loss: 0.0129 - acc: 0.9586 - val_loss: 0.0099 - val_acc: 0.9689\n",
      "Epoch 25/25\n",
      "29404/29404 [==============================] - 101s - loss: 0.0119 - acc: 0.9630 - val_loss: 0.0098 - val_acc: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126a25a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, private_dataset = load_data()\n",
    "(x_train, y_train), (x_test, y_test) = private_dataset\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(NUM_CLASSES),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9), \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/1\n",
      "30596/30596 [==============================] - 127s - loss: 0.6575 - acc: 0.7377 - val_loss: 0.1155 - val_acc: 0.9677\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 46s - loss: 0.6392 - acc: 0.7765 - val_loss: 0.2877 - val_acc: 0.9128\n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 45s - loss: 0.3464 - acc: 0.8867 - val_loss: 0.2041 - val_acc: 0.9358\n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 46s - loss: 0.2868 - acc: 0.9088 - val_loss: 0.1712 - val_acc: 0.9467\n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 56s - loss: 0.2560 - acc: 0.9178 - val_loss: 0.1528 - val_acc: 0.9529\n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 49s - loss: 0.2314 - acc: 0.9265 - val_loss: 0.1550 - val_acc: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c74a9b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_dataset, private_dataset = load_data()\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(NUM_CLASSES),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# pre-train on public dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = public_dataset\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))\n",
    "\n",
    "# fix lower layers\n",
    "\n",
    "for layer in feature_layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# train on private dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = private_dataset\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.0),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
